<!DOCTYPE html>
<html>

<head>
  <meta charset="utf-8">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <title>Hadoop环境搭建及单机、伪分布式安装问题总结（踩坑实录）</title>
  <link rel="stylesheet" href="https://stackedit.io/style.css" />
</head>

<body class="stackedit">
  <div class="stackedit__html"><h2><a id="Hadoop_0"></a>Hadoop环境搭建及单机、伪分布式安装问题总结（踩坑实录）</h2>
<p><em>2019-10-09 / 02:30:38</em></p>
<p>最近上了一门课，叫<strong>大数据基础</strong>，这是我第一次没有在别人的帮助下自己解决了如此多的问题，感谢<s>百度</s>，感谢<s>CSDN</s>，感谢各位大佬写的博客。我都觉得踩坑大队队长非我莫属了，怎么会有我这么笨的人，给我整懵了好了废话不多说记录一下我踩的坑。</p>
<h3><a id="_5"></a>实验名称</h3>
<ul>
<li>Hadoop单机配置及伪分布式安装</li>
</ul>
<h3><a id="_7"></a>实验环境</h3>
<ul>
<li>系统环境：Ubuntu 16.04.6</li>
<li>JAVA版本：java openjdk 1.8.0_222</li>
<li>Hadoop版本：Hadoop 3.2.1</li>
</ul>
<h3><a id="_12"></a>实验过程</h3>
<p>这个教程写的很好 <a href="http://dblab.xmu.edu.cn/blog/install-hadoop/">点击这里打开参考教程</a> 除了我自己笨让我踩了很多坑。</p>
<h3><a id="_17"></a>实验所遇问题</h3>
<blockquote>
<p>温馨提示：建议使用hadoop用户进行实验，否则可能会和我一样踩很多坑。</p>
</blockquote>
<ul>
<li>问题1：在解压Hadoop时出现如下问题，原因是有apt进程在运行</li>
</ul>
<pre><code class="prism language-powershell">tar <span class="token punctuation">(</span>child<span class="token punctuation">)</span>: <span class="token operator">/</span>home<span class="token operator">/</span>hadoop<span class="token operator">/</span>Downloads<span class="token operator">/</span>hadoop<span class="token operator">-</span>x<span class="token punctuation">.</span>x<span class="token punctuation">.</span>x<span class="token punctuation">.</span>tar<span class="token punctuation">.</span>gz: Cannot open: No such file or derectory
tar <span class="token punctuation">(</span>child<span class="token punctuation">)</span>:Error is not recoverable: exiting now
tar: Child returned status 2
tar: Error is not recoverable: exiting now
</code></pre>
<p>错误截图：<br>
<img src="https://img-blog.csdnimg.cn/20191009013806815.png" alt="在这里插入图片描述"></p>
<ul>
<li>解决办法：</li>
</ul>
<p>运行如下命令查看正在进行的进程</p>
<pre><code class="prism language-powershell"><span class="token function">ps</span> <span class="token operator">-</span>A <span class="token punctuation">|</span> grep apt
</code></pre>
<p>使用如下命令关闭进程</p>
<pre><code class="prism language-powershell">sudo <span class="token function">kill</span> <span class="token operator">-</span>9 number
</code></pre>
<p>例如：此处存在进程号为1142、1160的进程在运行，使用如下命令将其关闭。<br>
<img src="https://img-blog.csdnimg.cn/20191009013912955.png" alt="在这里插入图片描述"></p>
<ul>
<li>问题2：在执行grep例子时报错JAVA_HOME找不到，但是之前java环境都是配好的，使用“java -version”命令也可以查看到java的版本。</li>
</ul>
<pre><code class="prism language-powershell"> ERROR: JAVA_HOME is not <span class="token function">set</span> and could not be found<span class="token punctuation">.</span>
</code></pre>
<p>错误截图：<br>
<img src="https://img-blog.csdnimg.cn/20191009014314943.png" alt="在这里插入图片描述"></p>
<ul>
<li>解决办法：</li>
</ul>
<pre><code class="prism language-powershell">sudo vim hadoop<span class="token operator">/</span>etc<span class="token operator">/</span>hadoop<span class="token operator">/</span>hadoop<span class="token operator">-</span>env<span class="token punctuation">.</span>sh
</code></pre>
<p>使用上述语句修改 修改“hdoop-env.sh”文件中的</p>
<pre><code class="prism language-powershell"><span class="token comment"># export JAVA_HOME=</span>
</code></pre>
<p>这一行为</p>
<pre><code class="prism language-powershell"><span class="token comment"># export JAVA_HOME=/usr/lib/jvm/default-java</span>
</code></pre>
<p>并且添加</p>
<pre><code class="prism language-powershell"> export JAVA_HOME=<span class="token operator">/</span>usr<span class="token operator">/</span>lib<span class="token operator">/</span>jvm<span class="token operator">/</span>default<span class="token operator">-</span>java
</code></pre>
<p>（什么？找不到jdk的路径→<code>echo &amp;JAVA_HOME</code>）</p>
<p>实际修改如下：<br>
<img src="https://img-blog.csdnimg.cn/20191009015051418.png" alt="在这里插入图片描述"></p>
<ul>
<li>问题3：启动dfs时报错</li>
</ul>
<pre><code class="prism language-powershell">Starting namenodes on <span class="token namespace">[localhost]</span>
ERROR: Attempting to operate on hdfs namenode as root
ERROR: but there is no HDFS_NAMENODE_USER defined<span class="token punctuation">.</span> Aborting operation<span class="token punctuation">.</span>
Starting datanodes
ERROR: Attempting to operate on hdfs datanode as root
ERROR: but there is no HDFS_DATANODE_USER defined<span class="token punctuation">.</span> Aborting operation<span class="token punctuation">.</span>
Starting secondary namenodes <span class="token namespace">[slave1]</span>
ERROR: Attempting to operate on hdfs secondarynamenode as root
ERROR: but there is no HDFS_SECONDARYNAMENODE_USER defined<span class="token punctuation">.</span> Aborting operation<span class="token punctuation">.</span>
</code></pre>
<p>错误截图：<br>
<img src="https://img-blog.csdnimg.cn/20191009015635510.png" alt="在这里插入图片描述"></p>
<ul>
<li>解决办法：</li>
</ul>
<blockquote>
<p>如果不是用Hadoop启动的话，需将root改为对应用户</p>
</blockquote>
<p>以下是Hadoop3.2.1版本解决办法，如果你是Hadoop2.x.x版本请参考<a href="https://blog.csdn.net/lglglgl/article/details/80553828">这里点我点我</a><br>
在/hadoop/sbin路径下，将start-dfs.sh，stop-dfs.sh两个文件顶部添加以下参数：</p>
<pre><code class="prism language-powershell"><span class="token comment">#!/usr/bin/env bash</span>
HDFS_DATANODE_USER=root
HDFS_DATANODE_SECURE_USER=hdfs  
HDFS_NAMENODE_USER=root
HDFS_SECONDARYNAMENODE_USER=root
</code></pre>
<p>start-yarn.sh，stop-yarn.sh顶部也需添加以下参数：</p>
<pre><code class="prism language-powershell"><span class="token comment">#!/usr/bin/env bash</span>
YARN_RESOURCEMANAGER_USER=root
HADOOP_SECURE_DN_USER=yarn
YARN_NODEMANAGER_USER=root
</code></pre>
<p>修改后重启即可解决。</p>
<ul>
<li>问题4：以为上面那个问题解决了，重新启动dfs就没问题了，结果又报错了</li>
</ul>
<pre><code class="prism language-powershell"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
Starting namenodes on <span class="token namespace">[localhost]</span>
localhost: ERROR: Unable to <span class="token function">write</span> in <span class="token operator">/</span>usr<span class="token operator">/</span>local<span class="token operator">/</span>hadoop<span class="token operator">/</span>logs<span class="token punctuation">.</span> Aborting<span class="token punctuation">.</span>
Starting datanodes
localhost: ERROR: Unable to <span class="token function">write</span> in <span class="token operator">/</span>usr<span class="token operator">/</span>local<span class="token operator">/</span>hadoop<span class="token operator">/</span>logs<span class="token punctuation">.</span> Aborting<span class="token punctuation">.</span>
<span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre>
<p>错误截图：<img src="https://img-blog.csdnimg.cn/20191009020246701.png" alt="在这里插入图片描述"></p>
<ul>
<li>解决办法：<br>
此处Warning是由于问题3中新旧版本hadoop参数不对应造成的，后续已解决，可无视。<br>
出现Unable to write问题的原因是因为写入权限不够，因此需将权限给对应的文件夹<br>
执行如下代码：</li>
</ul>
<pre><code class="prism language-powershell">sudo chmod <span class="token operator">-</span>R 777 <span class="token operator">/</span>usr<span class="token operator">/</span>local<span class="token operator">/</span>hadoop<span class="token operator">/</span>logs
</code></pre>
<p>实际运行如下：<br>
<img src="https://img-blog.csdnimg.cn/20191009020759318.png" alt="在这里插入图片描述"></p>
<ul>
<li>问题5：我以为上面那个问题解决了，就真的没有问题了，结果给了权限以后又出现了Permission denied的问题。</li>
</ul>
<pre><code class="prism language-powershell"><span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
 Starting namenodes on <span class="token namespace">[localhost]</span>
 localhost: Permission denied <span class="token punctuation">(</span>publickey<span class="token punctuation">,</span>password<span class="token punctuation">)</span>
 Starting datanodes
 localhost: Permission denied <span class="token punctuation">(</span>publickey<span class="token punctuation">,</span>password<span class="token punctuation">)</span>
 <span class="token punctuation">.</span><span class="token punctuation">.</span><span class="token punctuation">.</span>
</code></pre>
<p>错误截图：<br>
<img src="https://img-blog.csdnimg.cn/20191009021022379.png" alt="在这里插入图片描述"></p>
<ul>
<li>解决办法：<br>
重新格式化节点，报错，重新配置ssh还是报错，在Permission denied一下午了之后我思考了一下到底是什么原因，此处总结为<strong>用户yubei没有对hadoop的操作权限</strong>，所以我是开错了账号，为了避免出现更多问题，我选择了最笨的办法→重新安装了虚拟机重做。（其实上面问题3中有一步需要修改root为实际调用用户yubei，尝试了一下没有成功，所以选择重来，如果是用hadoop用户不会有此问题）</li>
</ul>
<p>在重新安装虚拟机使用Hadoop用户进行实验后，实验变得顺畅了很多，遇到相同的问题都通过上面的办法解决了，接下来遇到一个新的问题。</p>
<ul>
<li>问题6：http://localhost:50070 端口错误打不开</li>
<li>解决办法：教程中的版本为Hadoop 2.x.x，我的版本是Hadoop 3.x.x，端口不同所以对不上。将端口修改为9870即可解决。即打开 http://localhost:9870<br>
<img src="https://img-blog.csdnimg.cn/20191009021722195.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjQyMjM0MQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li>
</ul>
<h3><a id="_155"></a>实验结果</h3>
<ul>
<li>单机配置运行实例grep结果如下：<br>
<img src="https://img-blog.csdnimg.cn/20191009021859802.png" alt="在这里插入图片描述"></li>
<li>伪分布式配置运行实例WordCount结果如下（部分截图）：<br>
<img src="https://img-blog.csdnimg.cn/20191009021956328.png?x-oss-process=image/watermark,type_ZmFuZ3poZW5naGVpdGk,shadow_10,text_aHR0cHM6Ly9ibG9nLmNzZG4ubmV0L3dlaXhpbl80MjQyMjM0MQ==,size_16,color_FFFFFF,t_70" alt="在这里插入图片描述"></li>
</ul>
<h3><a id="_160"></a>实验心得</h3>
<p>需要补一下Linux基础操作语句，遇到问题先<s>百度</s> 不要着急，静下心来你一定可以解决的。纠错联系右侧邮箱</p>
</div>
</body>

</html>
